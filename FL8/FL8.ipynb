{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "armed-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Using MNIST dataset, consider the following procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "breathing-majority",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "mnist data shape :  (70000, 784)\n",
      "mnist target shape :  (70000,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn.datasets as dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "mnist = dataset.fetch_openml('mnist_784')\n",
    "print(type(mnist.data))\n",
    "\n",
    "mnist_data = mnist.data.to_numpy()\n",
    "mnist_target = mnist.target.to_numpy()\n",
    "print('mnist data shape : ',mnist_data.shape)\n",
    "print('mnist target shape : ',mnist_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bacterial-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['5' '0' '4' ... '4' '5' '6']\n",
      "14780\n",
      "21770\n"
     ]
    }
   ],
   "source": [
    "#A. Randomly select 10,000 images for dataset. \n",
    "\n",
    "print(mnist_target)\n",
    "\n",
    "binary_idx = np.where( mnist_target < '2')\n",
    "Ternary_idx = np.where( mnist_target < '3')\n",
    "print(len(binary_idx[0]))\n",
    "print(len(Ternary_idx[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bound-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select(data, target, number=10000):\n",
    "    subset_idx = np.sort( np.random.choice(len(data), number,replace=False) )\n",
    "    \n",
    "    subset_data = data[subset_idx]\n",
    "    subset_target = target[subset_idx]\n",
    "    return subset_data, subset_target\n",
    "\n",
    "binary_data, binary_target  = select10000(mnist_data[binary_idx], mnist_target[binary_idx])\n",
    "ternary_data, ternary_target = select10000(mnist_data[Ternary_idx], mnist_target[Ternary_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "greater-medicaid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#B. Separate the dataset into training and test set. \n",
    "\n",
    "def separate(data,target,testset_rate=0.2):\n",
    "    rate = testset_rate\n",
    "\n",
    "    testset_idx = np.sort( np.random.choice(len(data), round( len(data)* rate),replace=False) )\n",
    "    trainingset_idx = np.sort( np.setdiff1d(np.arange(len(data)), testset_idx) )\n",
    "\n",
    "    #print('testset_idx \\n')\n",
    "    #print(testset_idx)\n",
    "    #print('\\n trainingset_idx \\n')\n",
    "    #print(trainingset_idx)\n",
    "\n",
    "    test_data = data[testset_idx]\n",
    "    test_target = target[testset_idx]\n",
    "\n",
    "    training_data = data[trainingset_idx]\n",
    "    training_target = target[trainingset_idx]\n",
    "\n",
    "    #print('\\n test set shape:  ', test_data.shape, test_target.shape )\n",
    "    #print('\\n training set shape:  ', training_data.shape, training_target.shape )\n",
    "    \n",
    "    return test_data, test_target, training_data,training_target\n",
    "\n",
    "binary_test_data, binary_test_target, binary_training_data, binary_training_target = separate(binary_data, binary_target)\n",
    "print()\n",
    "ternary_test_data, ternary_test_target, ternary_training_data, ternary_training_target = separate(ternary_data, ternary_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "sharing-modem",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy = 1.00\n",
      "\n",
      "Test set\n",
      "test data lenght:  2000 correct count:  1998\n",
      "accuracy:  99.9 %\n"
     ]
    }
   ],
   "source": [
    "#C. Train the data using SVM library. \n",
    "#D. Test the trained parameters using test set. \n",
    "from sklearn import svm\n",
    "binary = svm.SVC(kernel='linear',decision_function_shape='ovo')\n",
    "binary.fit(binary_training_data, binary_training_target)\n",
    "print('training set accuracy = %.2f' % binary.score(binary_training_data, binary_training_target))\n",
    "print()\n",
    "print('Test set')\n",
    "predict = binary.predict(binary_test_data)\n",
    "count = np.sum (predict == binary_test_target)\n",
    "print('test data lenght: ', len(binary_test_data), 'correct count: ', count)\n",
    "print('accuracy: ', 100*(count/len(binary_test_data)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "graduate-plumbing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy = 1.00\n",
      "\n",
      "Test set\n",
      "test data lenght:  2000 correct count:  1963\n",
      "accuracy:  98.15 %\n"
     ]
    }
   ],
   "source": [
    "ternary = svm.SVC(kernel='linear',decision_function_shape='ovr')\n",
    "ternary.fit(ternary_training_data, ternary_training_target)\n",
    "print('training set accuracy = %.2f' % ternary.score(ternary_training_data, ternary_training_target))\n",
    "print()\n",
    "print('Test set')\n",
    "predict = ternary.predict(ternary_test_data)\n",
    "count = np.sum (predict == ternary_test_target)\n",
    "print('test data lenght: ', len(ternary_test_target), 'correct count: ', count)\n",
    "print('accuracy: ', 100*(count/len(ternary_test_target)), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "sustained-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 training set accuracy = 1.00\n",
      "epoch 0 validation set accuracy = 0.90\n",
      "\n",
      "epoch 1 training set accuracy = 1.00\n",
      "epoch 1 validation set accuracy = 0.90\n",
      "\n",
      "epoch 2 training set accuracy = 1.00\n",
      "epoch 2 validation set accuracy = 0.89\n",
      "\n",
      "epoch 3 training set accuracy = 1.00\n",
      "epoch 3 validation set accuracy = 0.91\n",
      "\n",
      "epoch 4 training set accuracy = 1.00\n",
      "epoch 4 validation set accuracy = 0.90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#E. Repeat step B-D using k-fold (k=4) cross-validation method.\n",
    "\n",
    "subset_data, subset_target = select(mnist_data,mnist_target,20000)\n",
    "\n",
    "model = svm.SVC(kernel='linear',decision_function_shape='ovr')\n",
    "for i in range(5):\n",
    "    validation_test_data, validation_test_target,ternary_training_data, ternary_training_target = separate(subset_data, subset_target, testset_rate=0.25)\n",
    "    model.fit(ternary_training_data, ternary_training_target)\n",
    "    print('epoch', i ,'training set accuracy = %.2f' % model.score(ternary_training_data, ternary_training_target))\n",
    "    predict = ternary.predict(validation_test_data)\n",
    "    print('epoch', i ,'validation set accuracy = %.2f' % model.score(validation_test_data, validation_test_target))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-twist",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
